{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating the datasets...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/JDP/CS230_Visuomotor_Learning/parser/data/train_signs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-d2633df39b75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;31m# Get the filenames from the train and dev sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m train_filenames = [os.path.join(train_data_dir, f) for f in os.listdir(train_data_dir)\n\u001b[0m\u001b[1;32m     62\u001b[0m                    if f.endswith('.jpg')]\n\u001b[1;32m     63\u001b[0m eval_filenames = [os.path.join(dev_data_dir, f) for f in os.listdir(dev_data_dir)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/JDP/CS230_Visuomotor_Learning/parser/data/train_signs'"
     ]
    }
   ],
   "source": [
    "\"\"\"Train the model\"\"\"\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from model.input_fn import input_fn\n",
    "from model.utils import Params\n",
    "from model.utils import set_logger\n",
    "from model.utils import save_dict_to_json\n",
    "from model.model_fn import model_fn\n",
    "from model.training import train_and_evaluate\n",
    "\n",
    "\n",
    "# THE FOLLOWING ARE NOT NEEDED, LEGACY CODE USED FOR IMPORTING COMMAND LINE\n",
    "# ARGS. FROM STARTER CODE, KEPT HERE FOR REFERENCE\n",
    "# \n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--model_dir', default='experiments/test',\n",
    "#                     help=\"Experiment directory containing params.json\")\n",
    "# parser.add_argument('--data_dir', default='data/64x64_SIGNS',\n",
    "#                     help=\"Directory containing the dataset\")\n",
    "# parser.add_argument('--restore_from', default=None,\n",
    "#                     help=\"Optional, directory or file containing weights to reload before training\")\n",
    "\n",
    "\n",
    "# Set the random seed for the whole graph for reproductible experiments\n",
    "tf.set_random_seed(230)\n",
    "\n",
    "# Manually setting command line args here, used for setting paths for model and data\n",
    "args = {'model_dir': 'experiments/base_model',\n",
    "       'restore_from': None,\n",
    "       'data_dir':'data/JDP/CS230_Visuomotor_Learning/parser/data'}\n",
    "\n",
    "\n",
    "json_path = os.path.join(args['model_dir'], 'params.json')\n",
    "\n",
    "assert os.path.isfile(json_path), \"No json configuration file found at {}\".format(json_path)\n",
    "params = Params(json_path)\n",
    "# Check that we are not overwriting some previous experiment\n",
    "# Comment these lines if you are developing your model and don't care about overwritting\n",
    "model_dir_has_best_weights = os.path.isdir(os.path.join(args['model_dir'], \"best_weights\"))\n",
    "overwritting = model_dir_has_best_weights and args['restore_from'] is None\n",
    "assert not overwritting, \"Weights found in model_dir, aborting to avoid overwrite\"\n",
    "\n",
    "\n",
    "# Set the logger\n",
    "set_logger(os.path.join(args['model_dir'], 'train.log'))\n",
    "\n",
    "# Create the input data pipeline\n",
    "logging.info(\"Creating the datasets...\")\n",
    "data_dir = args['data_dir']\n",
    "train_data_dir = os.path.join(data_dir, \"train_signs\")\n",
    "dev_data_dir = os.path.join(data_dir, \"dev_signs\")\n",
    "\n",
    "\n",
    "# Get the filenames from the train and dev sets\n",
    "train_filenames = [os.path.join(train_data_dir, f) for f in os.listdir(train_data_dir)\n",
    "                   if f.endswith('.jpg')]\n",
    "eval_filenames = [os.path.join(dev_data_dir, f) for f in os.listdir(dev_data_dir)\n",
    "                  if f.endswith('.jpg')]\n",
    "\n",
    "# Labels will be between 0 and 5 included (6 classes in total)\n",
    "train_labels = [int(f.split('/')[-1][0]) for f in train_filenames]\n",
    "eval_labels = [int(f.split('/')[-1][0]) for f in eval_filenames]\n",
    "\n",
    "# Specify the sizes of the dataset we train on and evaluate on\n",
    "params.train_size = len(train_filenames)\n",
    "params.eval_size = len(eval_filenames)\n",
    "\n",
    "# Create the two iterators over the two datasets\n",
    "train_inputs = input_fn(True, train_filenames, train_labels, params)\n",
    "eval_inputs = input_fn(False, eval_filenames, eval_labels, params)\n",
    "\n",
    "# Define the model\n",
    "logging.info(\"Creating the model...\")\n",
    "train_model_spec = model_fn('train', train_inputs, params)\n",
    "eval_model_spec = model_fn('eval', eval_inputs, params, reuse=True)\n",
    "\n",
    "# Train the model\n",
    "logging.info(\"Starting training for {} epoch(s)\".format(params.num_epochs))\n",
    "train_and_evaluate(train_model_spec, eval_model_spec, args['model_dir'], params, args['restore_from'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
